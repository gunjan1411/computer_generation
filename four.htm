<body>
    <link rel="stylesheet" href="style.css">
    <div class="fourth1">

        <div id="fourth">
            <b>The Fourth Generation-Very Large Scale Integration (1980-?)</b>
        </div>
        <br>
        <hr>
        By the 1980s, VLSI (Very Large Scale Integration) had made it possible to.
        <div class="fourth">
            <img src="fo.1.jpg" alt="opps">
            <img src="fo.2.jpg" alt="opps">
        </div>
        put first tens of thousands, then hundreds of thousands, and finally millions of tran- sistors on a single
        chip.
        This development soon led to smaller and faster com- puters. Before the PDP-1, computers were so big and
        expensive that companies and universities had to have special departments called computer centers to run
        them.
        With the advent of the minicomputer, a department could buy its own com- puter. By 1980, prices had dropped
        so
        low that it was feasible for a single individ- ual to have his or her own computer. The personal computer
        era
        had begun.
        Personal computers were used in a very different way than large computers.
        They were used for word processing, spreadsheets, and numerous highly interac- tive applications (such as
        games)
        that the larger computers could not handle well.
        The first personal computers were usually sold as kits. Each kit contained a pnnted
        circuit board. a bunch of chips, typically including an Intel 8080, some cables, a power supply, and perhaps
        an
        8-inch floppy disk. Putting the parts toget her to make a computer was up to the purchaser. Software was not
        supplied. If you wanted any, you wrote your own. Later, the CP/M operating system, written by Gary Kildall.
        became popular on 8080s. It was a true (floppy) disk operating system, with a file system, and user commands
        typed in from the keyboard to a command processor (shel).
        Another early personal computer was the Apple and later the Apple II, de- signed by Steve Jobs and Steve
        Wozniak
        in the proverbial garage. This machine was enormously popular with home users and at schools and made Apple
        a
        serious player almost overnight.
        After much deliberating and observing what other companies were doing, 1BM, then the dominant force in the
        computer industry, finally decided it wanted to get into the personal computer business. Rather than design
        the
        entire machine from scratch, using only IBM parts, made from IBM transistors, made from IBM sand, which
        would
        have taken far too long, IBM did something quite uncharac tenstic. t gave an IBM executive, Philip Estridge,
        a
        large bag of money and told him to go build a personal computer far from the meddling bureaucrats at
        corporate
        headquarters in Armonk, NY. Estridge, working 2000 km away in Boca Raton,
        Florida, chose the Intel 8088 as his CPU, and built the IBM Personal Computer from commercial components. It
        was
        introduced in 1981 and instantly became the best-selling computer in history. When the PC hit 30, a number
        of
        articles about its history were published, including those by Bradley (2011), Goth (2011), Bride (2011), and
        Singh (2011).
        IBM also did something uncharacteristic that it would later come to regret.
        Rather than keeping the design of the machine totally secret (or at least, guarded by a gigantic and
        impenetrable wall of patents), as it normally did, it published the complete plans, including all the
        circuit
        diagrams, in a book that it sold for 549.
        The idea was to make it possible for other companies to make plug-in boards for the IBM PC, to increase its
        flexibility and popularity. Unfortunately for IBM, since the design was now completely public and all the
        parts
        were easily available from commercial vendors, numerous other companies began making clones of the
        PC, often for far less money than IBM was charging. Thus, an entire industry
        started.
        Although other companies made personal computers using non-Intel CPUs, in- cluding Commodore, Apple, and
        Atari,
        the momentum of the IBM PC industry was so large that the others were steamrollered. Only a few survived,
        and
        these were in niche markets.
        One that did survive, although barely, was the Apple Macintosh. The Macin- tosh was introduced in 1984 as
        the
        successor to the ill-fated Apple Lisa, which was the first computer to come with a GUI (Graphical User
        Interface), similar to the now-popular Windows interface. The Lisa failed because it was too expensive, but
        the lower-priced Macintosh introduced a year later was a huge success and inspired love
        and passion among its many admirers.
        The early personal computer market also led to the then-unheard of desire for portable computers. At that
        time,
        a portable computer made as much sense as a portable refrigerator does now. The first true portable personal
        computer was the
        Osborne-1, which at 11 kg was more of a luggable computer than a portable com- puter. Still, it proved that
        portables were possible. The Osborne-1 was a modest commercial success, but a year later Compaq brought out
        its
        first portable IBM PC clone and was quickly established as the leader in the market for portable com-
        puters.
        The initial version of the IBM PC came equipped with the MS-DOS operating system supplied by the then-tiny
        Microsoft Corporation. As Intel was able to pro- duce increasingly powerful CPUs, IBM and Microsoft were
        able to
        develop a suc- cessor to MS-DOS called OS/2, which featured a graphical user interface, similar to that of
        the
        Apple Macintosh. Meanwhile, Microsoft also developed its own operat ing system, Windows, which ran on top of
        MS-DOS, just in case OS/2 did not catch on. To make a long story short, OS/2 did not catch on, IBM and
        Microsoft
        had a big and extremely public falling out, and Microsoft went on to make Windows a huge success. How tiny
        Intel
        and even tinier Microsoft managed to dethrone IBM, one of the biggest, richest, and most powerful
        corporations
        in the history of the world, is a parable no doubt related in great detail in business schools around the
        globe.
        With the success of the 8088 in hand, Intel went on to make bigger and better versions of it. Particularly
        noteworthy was the 80386, released in 1985, which was a 32-bit CPU. This was followed by a souped-up
        version,
        naturally called the 80486. Subsequent versions went by the names Pentium and Core. These chips are used in
        nearly all modern PCs. The generic name many people use to describe the architecture of these processors is
        x86.
        The compatible chips manufactured by
        AMD are also called x86s.
        By the mid-1980s, a new development called RISC (discussed in Chap. 2) began to take over, replacing
        complicated
        (CISC) architectures with much simpler (but faster) ones. In the 1990s, superscalar CPUS began to appear.
        These
        ma- chines could execute multuple instructions at the same time, often in a different order than they
        appeared
        in the program. We will introduce the concepts of CISC.
        RISC, and superscalar in Chap. 2 and discuss them at length throughout this book.
        Also in the mid-1980s, Ross Freeman with his colleagues at Xilinx developed a clever approach to building
        integrated circuits that did not require wheelbarrows full of money or access to a silicon fabrication
        facility.
        This new kind of computer chip, called a field-programmable gate array (FPGA), contained a large supply of
        generic logic gates that could be " programmed into any circuit that tit into the device. This remarkable
        new
        approach to hardware design made FPGA hard ware as malleable as software. Using FPGAs that cost tens to
        hundreds
        of U.S. dollars, it became possible to build computing systems specialized for unique applications
        that served only a few users. Fortunately, silicon fabrication companies could still
        produce faster, lower-power and less expensive chips for applications that needed millions of chips. But,
        for
        applications with only a few users, such as prototyping low-volume design applications, and education, FPGAs
        remain a popular tool for building hardware.
        Up until 1992, personal computers were either 8-bit, 16-bit, or 32-bit. Then
        DEC came out with the revolutionary 64-bit Alpha, a true 64-bit RISC machine that outpertormed all other
        personal computers by a wide margin. It had a modest
        Success, but almost a decade elapsed before 64-bit machines began to catch on ina big way, and then mostly
        as
        high-end servers.
        Throughout the 1990s computing systems were getting faster and faster using a variety of microarchitectural
        optimizations, many of which we will examine in this book. Users of these systems were pampered by computer
        vendors, because each new system they bought would run their programs much faster than their old sys- tem.
        However, by the end of the 1990s this trend was beginning to wane because of two important obstacles in
        computer
        design: architects were running out of tricks to make programs faster, and the processors were getting too
        expensi1ve to cool.
        Desperate to continue building faster processors, most computer companies began turning toward parallel
        architectures as a way to squeeze out more pertormance from their silicon. In 2001 IBM introduced the POWER4
        dual-core architecture.
        This was the first time that a mainstream CPU incorporated two processors onto the same die. Today, most
        desktop
        and server class processors, and even some em- bedded processors, incorporate multiple processors on chip.
        The
        performance of these multiprocessors has unfortunately been less than stellar for the typical user, because
        (as
        we will see in later chapters) parallel machines require programmers to explicitly parallelize programs,
        which
        is a difficult and error-prone task.
    </div>
</body>